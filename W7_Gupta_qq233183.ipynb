{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre>Ashish Gupta</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre>Formed a study group with Isaac Aktam and Konrad Korzeniewski</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(123)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - Based on Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Build a classification model for the default of credit card clients dataset. More info here:\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "In week 3, you:\n",
    "- Explored the dataset\n",
    "- Built a full data pipeline\n",
    "- Pre-processed data, explored features\n",
    "\n",
    "Building on your work of week 3:\n",
    "- Split dataset into 3 sets:\n",
    "  - 70% -> Training and cross validation\n",
    "  - 15% -> Model Stacking\n",
    "  - 15% -> Testing\n",
    "  \n",
    "\n",
    "- Tune a decision tree classfier:\n",
    "  - select a score (http://scikit-learn.org/stable/modules/model_evaluation.html). Explain your choice \n",
    "  - tune one parameter a time. Generate a plot for the score vs parameter values. Analyze your results.\n",
    "    - criterion, max_depth, min_samples_split, min_samples_leaf, max_leaf_nodes=None    \n",
    "  - tune all parameters at the same time using a randomgrid(http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV). First, run with a coarse grid, then refine in the next iteration. Use the information from the previous step to select parameter values.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we choose the ROC-AUC as a score measure because:\n",
    "\n",
    " - AUC applies to binary classifiers\n",
    " - We want to choose hyperparameters with the highest AUC score so that we have a greater True Positives and a lower number of False Positives. Note: higher AUC score does not necessary lead to a higher accuracy score as can be seen in a case of a such hyperparameter as min_samples_split; therefore, we would need to sacrifice some AUC score for the accuracy score.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Set Information:\n",
    "\n",
    "This research aimed at the case of customers default payments in Taiwan and compares the predictive accuracy of \n",
    "probability of default among six data mining methods. From the perspective of risk management, the result of \n",
    "predictive accuracy of the estimated probability of default will be more valuable than the binary result of \n",
    "classification - credible or not credible clients. Because the real probability of default is unknown, this study \n",
    "presented the novel Sorting Smoothing Method to estimate the real probability of default. With the real \n",
    "probability of default as the response variable (Y), and the predictive probability of default as the independent \n",
    "variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by \n",
    "artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to \n",
    "zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural \n",
    "network is the only one that can accurately estimate the real probability of default.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. \n",
    "This study reviewed the literature and used the following 23 variables as explanatory variables: \n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her \n",
    "family (supplementary) credit. \n",
    "X2: Gender (1 = male; 2 = female). \n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "X5: Age (year). \n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. \n",
    "X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005. \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/\"\n",
    "CREDIT_PATH = os.path.join(\"datasets\", \"credit-default\")\n",
    "CREDIT_URL = DOWNLOAD_ROOT + \"default%20of%20credit%20card%20clients.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_creditdefault_data(credit_url=CREDIT_URL, credit_path=CREDIT_PATH):\n",
    "    if not os.path.isdir(credit_path):\n",
    "        os.makedirs(credit_path)\n",
    "    file_path = os.path.join(credit_path, \"default of credit card clients.xls\")\n",
    "    \n",
    "    urllib.request.urlretrieve(credit_url, file_path) \n",
    "    # The commented code above wont execute in proxy settings. Please download the files from Github\n",
    "    # https://github.com github.com/RoyMachineLearning/3253-Machine-Learning\n",
    "    \n",
    "fetch_creditdefault_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_CRDEFAULT_data(credit_path=CREDIT_PATH):\n",
    "    file_path = os.path.join(credit_path, \"default of credit card clients.xls\")\n",
    "    return pd.read_excel(file_path, sheet = 0, skiprows= 1, header = 0)\n",
    "\n",
    "df = load_CRDEFAULT_data()\n",
    "df = df.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data into Training, Model Stacking and test\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.3, random_state = 123)\n",
    "for train_index, Not_Train_index in split.split(df, df[\"default payment next month\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    Not_Train_set = df.loc[Not_Train_index]\n",
    "    \n",
    "# Second split\n",
    "new_split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.5, random_state = 123)\n",
    "for stack_index, test_index in new_split.split(Not_Train_set, Not_Train_set[\"default payment next month\"]):\n",
    "    strat_stack_set = df.loc[stack_index]\n",
    "    strat_test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The x variable for training set\n",
    "training_df_X = strat_train_set.drop(\"default payment next month\", axis=1)\n",
    "\n",
    "#the Y Variable\n",
    "training_df_Y = strat_train_set[\"default payment next month\"].copy()\n",
    "\n",
    "# The x variable for Model Stacking set\n",
    "ModelStacking_df_X = strat_stack_set.drop(\"default payment next month\", axis=1)\n",
    "\n",
    "#the Y Variable\n",
    "ModelStacking_df_Y = strat_stack_set[\"default payment next month\"].copy()\n",
    "\n",
    "# The x variable for test set\n",
    "test_df_X = strat_test_set.drop(\"default payment next month\", axis=1)\n",
    "\n",
    "#the Y Variable\n",
    "test_df_Y = strat_test_set[\"default payment next month\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the Plots for Checking the roc_auc values vs Parameter\n",
    "\n",
    "def plot_Parameters_Vs_Scores(criterion_estimators,roc_auc_values,plotType):\n",
    "    if plotType == \"Scatter\":\n",
    "        plt.scatter(criterion_estimators, roc_auc_values)\n",
    "    if plotType == \"Line\":\n",
    "        plt.plot(criterion_estimators, roc_auc_values) \n",
    "    plt.xlabel(\"Parameters Vs AUC Scores\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluate the Decision tree model on the training set\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "criterion_estimators_1 = ['gini', 'entropy']\n",
    "\n",
    "#Establish the first Parameter.\n",
    "roc_auc_values = []\n",
    "\n",
    "for item in criterion_estimators_1:\n",
    "    Dtree_clf = DecisionTreeClassifier(criterion=item, random_state=42)\n",
    "    Dtree_clf.fit(training_df_X, training_df_Y)\n",
    "\n",
    "    y_probas_trees = cross_val_predict(Dtree_clf,training_df_X,training_df_Y, cv=4, method=\"predict_proba\")\n",
    "    y_tree_scores = y_probas_trees[:, 1] # score = proba of positive class\n",
    "    roc_auc_trees = roc_auc_score(training_df_Y,y_tree_scores)\n",
    "    roc_auc_values.append(roc_auc_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyiFhZmalHBJmZlbKIWFmZqX+H5TGWyBewGuFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfe62e3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Parameters_Vs_Scores(criterion_estimators_1, roc_auc_values,\"Scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "param_grid_forest_1 = {'criterion' : criterion_estimators_1}\n",
    "grid_search_1 = GridSearchCV(Dtree_clf, param_grid_forest_1, cv = 4, scoring='roc_auc', refit = True)\n",
    "grid_search_1.fit(training_df_X, training_df_Y)\n",
    "\n",
    "best_params_1 = grid_search_1.best_params_\n",
    "best_estimators_1 = grid_search_1.best_estimator_\n",
    "\n",
    "print(best_params_1)\n",
    "print(best_estimators_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999476190476\n"
     ]
    }
   ],
   "source": [
    "#Print the accuracy score\n",
    "print(best_estimators_1.score(training_df_X,training_df_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918888888889\n"
     ]
    }
   ],
   "source": [
    "#Check the Accuracy on Test data \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_estimations_1 = best_estimators_1.predict(test_df_X)\n",
    "print(accuracy_score(test_df_Y, y_test_estimations_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the accuracy drops on the test set - this criterion parameter may not be sufficient enough be a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criterion Parameter - Max Depth\n",
    "\n",
    "criterion_estimators_2 = [1, 2, 3, 4, 5]\n",
    "\n",
    "roc_auc_values = []\n",
    "\n",
    "for item in criterion_estimators_2:\n",
    "    Dtree_clf = DecisionTreeClassifier(max_depth=item, random_state=42)\n",
    "    Dtree_clf.fit(training_df_X, training_df_Y)\n",
    "\n",
    "    y_probas_trees = cross_val_predict(Dtree_clf,training_df_X,training_df_Y, cv=4, method=\"predict_proba\")\n",
    "    y_tree_scores = y_probas_trees[:, 1] # score = proba of positive class\n",
    "    roc_auc_trees = roc_auc_score(training_df_Y,y_tree_scores)\n",
    "    roc_auc_values.append(roc_auc_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZcyqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfe633a940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Parameters_Vs_Scores(criterion_estimators_2, roc_auc_values,\"Line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "param_grid_forest_2 = {'max_depth' : criterion_estimators_2}\n",
    "grid_search_2 = GridSearchCV(Dtree_clf, param_grid_forest_2, cv = 4, scoring='roc_auc', refit = True)\n",
    "grid_search_2.fit(training_df_X, training_df_Y)\n",
    "\n",
    "best_params_2 = grid_search_2.best_params_\n",
    "best_estimators_2 = grid_search_2.best_estimator_\n",
    "\n",
    "print(best_params_2)\n",
    "print(best_estimators_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823285714286\n"
     ]
    }
   ],
   "source": [
    "#Print the accuracy score\n",
    "print(best_estimators_2.score(training_df_X,training_df_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807333333333\n"
     ]
    }
   ],
   "source": [
    "#Check the Accuracy on Test data \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_estimations_2 = best_estimators_2.predict(test_df_X)\n",
    "print(accuracy_score(test_df_Y, y_test_estimations_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the accuracy drops on the test set - this criterion parameter may not be sufficient enough be a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criterion = Min Samples Split.\n",
    "criterion_estimators_3 = list(range(2,10))\n",
    "\n",
    "roc_auc_values = []\n",
    "\n",
    "for item in criterion_estimators_3:\n",
    "    Dtree_clf = DecisionTreeClassifier(min_samples_split=item, random_state=42)\n",
    "    Dtree_clf.fit(training_df_X, training_df_Y)\n",
    "\n",
    "    y_probas_trees = cross_val_predict(Dtree_clf,training_df_X,training_df_Y, cv=4, method=\"predict_proba\")\n",
    "    y_tree_scores = y_probas_trees[:, 1] # score = proba of positive class\n",
    "    roc_auc_trees = roc_auc_score(training_df_Y,y_tree_scores)\n",
    "    roc_auc_values.append(roc_auc_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfe633a668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Parameters_Vs_Scores(criterion_estimators_3, roc_auc_values,\"Line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 9}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=9,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "#Set the min_samples_split to None as this parameter keeps increasing at a decreasing rate.But a higher score\n",
    "# is generated with 20 as min sample split\n",
    "param_grid_forest_3 = {'min_samples_split' : criterion_estimators_3}\n",
    "grid_search_3 = GridSearchCV(Dtree_clf, param_grid_forest_3, cv = 4, scoring='roc_auc', refit = True)\n",
    "grid_search_3.fit(training_df_X, training_df_Y)\n",
    "\n",
    "best_params_3 = grid_search_3.best_params_\n",
    "best_estimators_3 = grid_search_3.best_estimator_\n",
    "\n",
    "print(best_params_3)\n",
    "print(best_estimators_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941095238095\n"
     ]
    }
   ],
   "source": [
    "#Print the accuracy score\n",
    "print(best_estimators_3.score(training_df_X,training_df_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879111111111\n"
     ]
    }
   ],
   "source": [
    "#Check the Accuracy on Test data \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_estimations_3 = best_estimators_3.predict(test_df_X)\n",
    "print(accuracy_score(test_df_Y, y_test_estimations_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the accuracy drops on the test set - this criterion parameter may not be sufficient enough be a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criteria : min_samples_leaf\n",
    "criterion_estimators_4 = [(i + 1) / 10 for i in range(5)]\n",
    "\n",
    "roc_auc_values = []\n",
    "\n",
    "for item in criterion_estimators_4:\n",
    "    Dtree_clf = DecisionTreeClassifier(min_samples_leaf=item, random_state=42)\n",
    "    Dtree_clf.fit(training_df_X, training_df_Y)\n",
    "\n",
    "    y_probas_trees = cross_val_predict(Dtree_clf,training_df_X,training_df_Y, cv=4, method=\"predict_proba\")\n",
    "    y_tree_scores = y_probas_trees[:, 1] # score = proba of positive class\n",
    "    roc_auc_trees = roc_auc_score(training_df_Y,y_tree_scores)\n",
    "    roc_auc_values.append(roc_auc_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfe5aa6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Parameters_Vs_Scores(criterion_estimators_4, roc_auc_values,\"Line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 0.1}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=0.1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "param_grid_forest_4 = {'min_samples_leaf' : criterion_estimators_4}\n",
    "grid_search_4 = GridSearchCV(Dtree_clf, param_grid_forest_4, cv = 4, scoring='roc_auc', refit = True)\n",
    "grid_search_4.fit(training_df_X, training_df_Y)\n",
    "\n",
    "best_params_4 = grid_search_4.best_params_\n",
    "best_estimators_4 = grid_search_4.best_estimator_\n",
    "\n",
    "print(best_params_4)\n",
    "print(best_estimators_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818\n"
     ]
    }
   ],
   "source": [
    "#Print the accuracy score\n",
    "print(best_estimators_4.score(training_df_X,training_df_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804444444444\n"
     ]
    }
   ],
   "source": [
    "#Check the Accuracy on Test data \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_estimations_4 = best_estimators_4.predict(test_df_X)\n",
    "print(accuracy_score(test_df_Y, y_test_estimations_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the models we have build so far, The Hyper parameter \"min_samples_leaf\" generates a good accuracy over the test set\n",
    "when compared to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criterion = max_leaf_nodes\n",
    "criterion_estimators_5 = list(range(2, 35))\n",
    "\n",
    "roc_auc_values = []\n",
    "\n",
    "for item in criterion_estimators_5:\n",
    "    Dtree_clf = DecisionTreeClassifier(max_leaf_nodes=item, random_state=42)\n",
    "    Dtree_clf.fit(training_df_X, training_df_Y)\n",
    "\n",
    "    y_probas_trees = cross_val_predict(Dtree_clf,training_df_X,training_df_Y, cv=4, method=\"predict_proba\")\n",
    "    y_tree_scores = y_probas_trees[:, 1] # score = proba of positive class\n",
    "    roc_auc_trees = roc_auc_score(training_df_Y,y_tree_scores)\n",
    "    roc_auc_values.append(roc_auc_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhARiTklAhGRmPv/s85z4n9qeeYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfe5ab5da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Parameters_Vs_Scores(criterion_estimators_5, roc_auc_values,\"Line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_leaf_nodes': 33}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=33,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "param_grid_forest_5 = {'max_leaf_nodes' : criterion_estimators_5}\n",
    "grid_search_5 = GridSearchCV(Dtree_clf, param_grid_forest_5, cv = 4, scoring='roc_auc', refit = True)\n",
    "grid_search_5.fit(training_df_X, training_df_Y)\n",
    "\n",
    "best_params_5 = grid_search_5.best_params_\n",
    "best_estimators_5 = grid_search_5.best_estimator_\n",
    "\n",
    "print(best_params_5)\n",
    "print(best_estimators_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822857142857\n"
     ]
    }
   ],
   "source": [
    "#Print the accuracy score\n",
    "print(best_estimators_5.score(training_df_X,training_df_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805555555556\n"
     ]
    }
   ],
   "source": [
    "#Check the Accuracy on Test data \n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test_estimations_5 = best_estimators_5.predict(test_df_X)\n",
    "print(accuracy_score(test_df_Y, y_test_estimations_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the accuracy drops on the test set - this criterion parameter may not be sufficient enough be a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune all parameters at the same time using a randomgrid(http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV). First, run with a coarse grid, then refine in the next iteration. Use the information from the previous step to select parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=25, max_depth=3, criterion=gini \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=25, max_depth=3, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=25, max_depth=3, criterion=gini \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=25, max_depth=3, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=25, max_depth=3, criterion=gini \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=25, max_depth=3, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.1, max_leaf_nodes=29, max_depth=4, criterion=entropy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=8, min_samples_leaf=0.1, max_leaf_nodes=29, max_depth=4, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.1, max_leaf_nodes=29, max_depth=4, criterion=entropy \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.1, max_leaf_nodes=29, max_depth=4, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.1, max_leaf_nodes=29, max_depth=4, criterion=entropy \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.1, max_leaf_nodes=29, max_depth=4, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=4, min_samples_leaf=0.4, max_leaf_nodes=2, max_depth=2, criterion=gini \n",
      "[CV]  min_samples_split=4, min_samples_leaf=0.4, max_leaf_nodes=2, max_depth=2, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=4, min_samples_leaf=0.4, max_leaf_nodes=2, max_depth=2, criterion=gini \n",
      "[CV]  min_samples_split=4, min_samples_leaf=0.4, max_leaf_nodes=2, max_depth=2, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=4, min_samples_leaf=0.4, max_leaf_nodes=2, max_depth=2, criterion=gini \n",
      "[CV]  min_samples_split=4, min_samples_leaf=0.4, max_leaf_nodes=2, max_depth=2, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=6, min_samples_leaf=0.2, max_leaf_nodes=11, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=6, min_samples_leaf=0.2, max_leaf_nodes=11, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=6, min_samples_leaf=0.2, max_leaf_nodes=11, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=6, min_samples_leaf=0.2, max_leaf_nodes=11, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=6, min_samples_leaf=0.2, max_leaf_nodes=11, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=6, min_samples_leaf=0.2, max_leaf_nodes=11, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=4, min_samples_leaf=0.3, max_leaf_nodes=33, max_depth=4, criterion=gini \n",
      "[CV]  min_samples_split=4, min_samples_leaf=0.3, max_leaf_nodes=33, max_depth=4, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=4, min_samples_leaf=0.3, max_leaf_nodes=33, max_depth=4, criterion=gini \n",
      "[CV]  min_samples_split=4, min_samples_leaf=0.3, max_leaf_nodes=33, max_depth=4, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=4, min_samples_leaf=0.3, max_leaf_nodes=33, max_depth=4, criterion=gini \n",
      "[CV]  min_samples_split=4, min_samples_leaf=0.3, max_leaf_nodes=33, max_depth=4, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=5, min_samples_leaf=0.1, max_leaf_nodes=31, max_depth=1, criterion=entropy \n",
      "[CV]  min_samples_split=5, min_samples_leaf=0.1, max_leaf_nodes=31, max_depth=1, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=5, min_samples_leaf=0.1, max_leaf_nodes=31, max_depth=1, criterion=entropy \n",
      "[CV]  min_samples_split=5, min_samples_leaf=0.1, max_leaf_nodes=31, max_depth=1, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=5, min_samples_leaf=0.1, max_leaf_nodes=31, max_depth=1, criterion=entropy \n",
      "[CV]  min_samples_split=5, min_samples_leaf=0.1, max_leaf_nodes=31, max_depth=1, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=3, min_samples_leaf=0.4, max_leaf_nodes=15, max_depth=3, criterion=entropy \n",
      "[CV]  min_samples_split=3, min_samples_leaf=0.4, max_leaf_nodes=15, max_depth=3, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=3, min_samples_leaf=0.4, max_leaf_nodes=15, max_depth=3, criterion=entropy \n",
      "[CV]  min_samples_split=3, min_samples_leaf=0.4, max_leaf_nodes=15, max_depth=3, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=3, min_samples_leaf=0.4, max_leaf_nodes=15, max_depth=3, criterion=entropy \n",
      "[CV]  min_samples_split=3, min_samples_leaf=0.4, max_leaf_nodes=15, max_depth=3, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=21, max_depth=1, criterion=entropy \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=21, max_depth=1, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=21, max_depth=1, criterion=entropy \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=21, max_depth=1, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=21, max_depth=1, criterion=entropy \n",
      "[CV]  min_samples_split=8, min_samples_leaf=0.3, max_leaf_nodes=21, max_depth=1, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=3, min_samples_leaf=0.3, max_leaf_nodes=16, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=3, min_samples_leaf=0.3, max_leaf_nodes=16, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=3, min_samples_leaf=0.3, max_leaf_nodes=16, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=3, min_samples_leaf=0.3, max_leaf_nodes=16, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=3, min_samples_leaf=0.3, max_leaf_nodes=16, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=3, min_samples_leaf=0.3, max_leaf_nodes=16, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=0.3, max_leaf_nodes=4, max_depth=1, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=0.3, max_leaf_nodes=4, max_depth=1, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=0.3, max_leaf_nodes=4, max_depth=1, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=0.3, max_leaf_nodes=4, max_depth=1, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=0.3, max_leaf_nodes=4, max_depth=1, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=0.3, max_leaf_nodes=4, max_depth=1, criterion=gini, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=34,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9], 'min_samples_leaf': [0.1, 0.2, 0.3, 0.4, 0.5], 'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning all the parameters together \n",
    "parameter_distribution = {'criterion' : criterion_estimators_1, 'max_depth' : criterion_estimators_2,\n",
    "                          'min_samples_split' : criterion_estimators_3, 'min_samples_leaf' : criterion_estimators_4,\n",
    "                          'max_leaf_nodes' : criterion_estimators_5}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(Dtree_clf, parameter_distribution, n_iter=10, verbose=2)\n",
    "rnd_search_cv.fit(training_df_X, training_df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81799999999999995"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the best estimator on Randomized SearchCV\n",
    "rnd_search_cv.best_estimator_\n",
    "rnd_search_cv.score(training_df_X,training_df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804444444444\n"
     ]
    }
   ],
   "source": [
    "# Based on the accuracy scores, we select the best estimator and work with the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "final_model = rnd_search_cv.best_estimator_ #best estimator with accuracy over 99%\n",
    "\n",
    "y_test_estimations = final_model.predict(test_df_X)\n",
    "\n",
    "print(accuracy_score(test_df_Y, y_test_estimations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Q1. Decision Tree performs the best under the hyperparameter , {'criterion': 'entropy'} on the training set. But when we compare the model accuracy on the test set. The Accuracy drops considerably - indicating an instance of clear overfitting on the\n",
    "training set. Thus a higher accuracy is not the only measure. \n",
    "\n",
    "Whereas The Hyper parameter \"min_samples_leaf\" generates a good accuracy over the test set when compared to the training set.\n",
    "Although the accuracy number is low, but this is a more useful model when compared to other models. \n",
    "\n",
    "When we run all the Hyper parameters using randomized search, The model is slightly overfitted. But it is a recommended approach to use with the right number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning\n",
    "\n",
    "Make sure to read and understand the documentation for each classifier.\n",
    "\n",
    "Remember to make your code modular; it will save you rewriting the same things multiple times and will help avoid copy paste errors.\n",
    "\n",
    "\n",
    "  \n",
    "- Tune the following classifiers:\n",
    "  - Random forest classfier\n",
    "  - Adaboost Tree classifier\n",
    "  - Extra trees classifier\n",
    "  - Gradient Boosted Tree classifier\n",
    "  - Logistic Regression\n",
    "  \n",
    "- Analyze, compare, and interpret your results\n",
    "- What ensemble yields the best result? Can you identify certain types of events that are classified better/worse from the type of algorithm?\n",
    "- Is the feature importance consistent for all classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3.5\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Owner\\Anaconda3.5\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the data and create pipeline\n",
    "\n",
    "#create the list to be transformed - Credit DF\n",
    "training_df_NonTransform = training_df[['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']]\n",
    "training_df_Transform = training_df[['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2','BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6' ]]\n",
    "\n",
    "#retrieve the column names dropped\n",
    "#training_df_columns_labels =  training_df_Transform.columns.values.tolist()\n",
    "\n",
    "#Create numerical pipeline to transform numerical values\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Convert the non transformed Dataframe into list.\n",
    "training_df_NonTransform_list = list(training_df_NonTransform)\n",
    "training_df_Transform_list = list(training_df_Transform)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(training_df_Transform_list)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(training_df_NonTransform_list))\n",
    "    ])\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"cat_pipeline\", cat_pipeline),    \n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    ])\n",
    "\n",
    "Final_training_X = full_pipeline.fit_transform(training_df_X)\n",
    "Final_stack_X = full_pipeline.fit_transform(ModelStacking_df_X)\n",
    "Final_test_X = full_pipeline.transform(test_df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the libraries for all the classifiers.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 288 candidates, totalling 1152 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1152 out of 1152 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 0.5, 'max_leaf_nodes': 10, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1, 'n_estimators': 200, 'oob_score': True}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.5, max_leaf_nodes=10,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=0.1, min_samples_split=0.1,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=True, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Design the random forest classifier\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "n_estimators = [10, 200]\n",
    "max_features = [0.1, 0.5]\n",
    "max_depth = [2, 10, 20] \n",
    "oob_score = [True, False]\n",
    "min_samples_split = [0.1, 0.5]\n",
    "min_samples_leaf = [0.1, 0.5]\n",
    "max_leaf_nodes = [2, 10, 100]\n",
    "\n",
    "parameter_random_forest = {'n_estimators' : n_estimators, 'max_features' : max_features,\n",
    "                     'max_depth' : max_depth, 'min_samples_split' : min_samples_split,\n",
    "                    'oob_score' : oob_score, 'min_samples_leaf': min_samples_leaf, \n",
    "                     'max_leaf_nodes' : max_leaf_nodes}\n",
    "             \n",
    "Random_Forest_Classifier = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#use grid search to tune the model\n",
    "\n",
    "grid_search_RndmForest = GridSearchCV(Random_Forest_Classifier,parameter_random_forest, cv = 4, scoring='roc_auc', refit = True,\n",
    "                                     n_jobs = -1, verbose=2)\n",
    "\n",
    "grid_search_RndmForest.fit(Final_training_X,training_df_Y)\n",
    "             \n",
    "forest_best_params_ = grid_search_RndmForest.best_params_\n",
    "forest_best_estimators_ = grid_search_RndmForest.best_estimator_\n",
    "\n",
    "print(forest_best_params_)\n",
    "print(forest_best_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774888888889\n"
     ]
    }
   ],
   "source": [
    "#Now Predict on the Stack Dataset\n",
    "Random_Forest_estimators = forest_best_estimators_\n",
    "y_estimator_forest = Random_Forest_estimators.predict(Final_stack_X)\n",
    "print(accuracy_score(ModelStacking_df_Y, y_estimator_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776222222222\n"
     ]
    }
   ],
   "source": [
    "# Test on the Test Data\n",
    "y_final_estimator_forest = Random_Forest_estimators.predict(Final_test_X)\n",
    "print(accuracy_score(test_df_Y, y_final_estimator_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a better accuracy on the test set when compared with the training set, Random Forest proves out to be a good classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify certain types of events that are classified better/worse from this classifier - we use the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3487,    0],\n",
       "       [1013,    0]], dtype=int64)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the stack set for Random Forest Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ModelStacking_df_Y, y_estimator_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3493,    0],\n",
       "       [1007,    0]], dtype=int64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the test set for Random Forest Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_df_Y, y_final_estimator_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that We have got increased True Positives (more customer's defaulting) and reduced false positives - from stacked / validation set to test set. This also indicates a better accuracy achieved on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we capture the feature importance for the random forest classifer - sorted in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX 0.0\n",
      "PAY_2 0.0\n",
      "PAY_4 0.0\n",
      "LIMIT_BAL 2.81358049379e-05\n",
      "PAY_6 4.99291287047e-05\n",
      "EDUCATION 0.000212320694719\n",
      "BILL_AMT4 0.00091263474512\n",
      "BILL_AMT5 0.00133570010001\n",
      "PAY_3 0.00140259664563\n",
      "AGE 0.00205676800682\n",
      "PAY_0 0.00220648491687\n",
      "BILL_AMT3 0.00321045824914\n",
      "BILL_AMT6 0.00334079951297\n",
      "BILL_AMT2 0.00489613021661\n",
      "PAY_AMT5 0.00491729445122\n",
      "BILL_AMT1 0.00677123075075\n",
      "PAY_AMT6 0.00693381567949\n",
      "PAY_AMT4 0.0165562094364\n",
      "PAY_AMT3 0.0586180946003\n",
      "PAY_AMT2 0.0867698487916\n",
      "PAY_5 0.186237237022\n",
      "PAY_AMT1 0.186515342298\n",
      "MARRIAGE 0.427028968948\n"
     ]
    }
   ],
   "source": [
    "for name, score in sorted(zip(ModelStacking_df_X.columns, Random_Forest_estimators.feature_importances_), key=lambda x: x[1]):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   18.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.05, 'n_estimators': 20}\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.05, n_estimators=20, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Now Build the ADA Boost Classifier\n",
    "\n",
    "n_estimators = [5, 10, 15, 20]\n",
    "learning_rate = [0.05, 0.01]\n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "\n",
    "Ada_Classifer = AdaBoostClassifier(random_state = 42)\n",
    "parameter_Ada_Classifer = {'n_estimators' : n_estimators, 'learning_rate' : learning_rate, 'algorithm' : algorithm}\n",
    "grid_search_AdaClassifier = GridSearchCV(Ada_Classifer, parameter_Ada_Classifer, cv = 4, scoring='roc_auc', refit = True, n_jobs = -1, verbose = 2)\n",
    "grid_search_AdaClassifier.fit(Final_training_X,training_df_Y)\n",
    "\n",
    "AdaClassifier_best_params_ = grid_search_AdaClassifier.best_params_\n",
    "AdaClassifier_best_estimators_ = grid_search_AdaClassifier.best_estimator_\n",
    "print(AdaClassifier_best_params_)\n",
    "print(AdaClassifier_best_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810666666667\n"
     ]
    }
   ],
   "source": [
    "#check accuracy on stack dataset\n",
    "AdaClassifier_Estimators = AdaClassifier_best_estimators_\n",
    "y_estimator_ada = AdaClassifier_Estimators.predict(Final_stack_X)\n",
    "print(accuracy_score(ModelStacking_df_Y, y_estimator_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804444444444\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on the Test Data\n",
    "y_final_estimator_ada = AdaClassifier_Estimators.predict(Final_test_X)\n",
    "print(accuracy_score(test_df_Y, y_final_estimator_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we identify certain types of events that are classified better/worse from ADA classifier - we use the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3370,  117],\n",
       "       [ 771,  242]], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the stack set for ADA Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ModelStacking_df_Y, y_estimator_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3220,  273],\n",
       "       [ 921,   86]], dtype=int64)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the test set for ADA Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_df_Y, y_final_estimator_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that We have got decreased True Positives and false negatives (less customer's defaulting) - from stacked / validation set to test set. This also indicates a better accuracy achieved on test set. Also the False positives and true negatives have increased, leading to a higher misclassification rate and lower accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the model accuracy for ADA Classifier is lower on the Test Set. The Lower variance could be due to the number of hyper parameters and their values. It is always recommended to check different hyper parameters. The model thus is still performing well and is not a case of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we capture the feature importance for the Ada Classifer - Sorted in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BAL 0.0\n",
      "SEX 0.0\n",
      "EDUCATION 0.0\n",
      "PAY_2 0.0\n",
      "PAY_3 0.0\n",
      "PAY_4 0.0\n",
      "PAY_5 0.0\n",
      "PAY_6 0.0\n",
      "BILL_AMT1 0.0\n",
      "BILL_AMT2 0.0\n",
      "BILL_AMT3 0.0\n",
      "BILL_AMT4 0.0\n",
      "BILL_AMT5 0.0\n",
      "BILL_AMT6 0.0\n",
      "PAY_AMT1 0.0\n",
      "PAY_AMT2 0.0\n",
      "PAY_AMT3 0.0\n",
      "PAY_AMT4 0.0\n",
      "PAY_AMT5 0.0\n",
      "PAY_AMT6 0.0\n",
      "PAY_0 0.1\n",
      "AGE 0.15\n",
      "MARRIAGE 0.75\n"
     ]
    }
   ],
   "source": [
    "for name, score in sorted(zip(ModelStacking_df_X.columns, AdaClassifier_Estimators.feature_importances_), key=lambda x: x[1]):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 144 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 50, 'max_features': 0.5, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1, 'n_estimators': 200}\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=50, max_features=0.5, max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=0.1, min_samples_split=0.1,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# The next we build is an Extra Trees Classifier\n",
    "\n",
    "Extra_Classifier = ExtraTreesClassifier(random_state = 42)\n",
    "\n",
    "n_estimators = [3, 70, 100, 200]\n",
    "max_features = [0.1,0.3,0.5]\n",
    "max_depth = [2, 50, 70]\n",
    "min_samples_split = [0.1, 0.5]\n",
    "min_samples_leaf = [0.1, 0.5] # Mhm, this one leads to accuracy of test and train sets being the same.\n",
    "\n",
    "parameter_Extra_Classifier = {'n_estimators' : n_estimators, 'max_features' : max_features,\n",
    "                         'max_depth' : max_depth, 'min_samples_split' : min_samples_split,\n",
    "                         'min_samples_leaf' : min_samples_leaf}\n",
    "\n",
    "grid_search_ExtraClassifier = GridSearchCV(Extra_Classifier, parameter_Extra_Classifier, cv = 4, scoring='roc_auc', \n",
    "                               refit = True, n_jobs = -1, verbose = 2)\n",
    "grid_search_ExtraClassifier.fit(Final_training_X,training_df_Y)\n",
    "\n",
    "Extra_Classifier_best_params_ = grid_search_ExtraClassifier.best_params_\n",
    "Extra_Classifier_best_estimators_ = grid_search_ExtraClassifier.best_estimator_\n",
    "print(Extra_Classifier_best_params_)\n",
    "print(Extra_Classifier_best_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774888888889\n"
     ]
    }
   ],
   "source": [
    "#check accuracy on stack data\n",
    "ExtraClassifier_Estimators = Extra_Classifier_best_estimators_\n",
    "y_estimator_extra = ExtraClassifier_Estimators.predict(Final_stack_X)\n",
    "print(accuracy_score(ModelStacking_df_Y, y_estimator_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776222222222\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy on the Test Data\n",
    "y_final_estimator_extra = ExtraClassifier_Estimators.predict(Final_test_X)\n",
    "print(accuracy_score(test_df_Y, y_final_estimator_extra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we identify certain types of events that are classified better/worse from Extra Trees classifier - we use the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3487,    0],\n",
       "       [1013,    0]], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the stack set for Extra Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ModelStacking_df_Y, y_estimator_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3493,    0],\n",
       "       [1007,    0]], dtype=int64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the test set for Extra Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_df_Y, y_final_estimator_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Random Forest, Extra Classifier receives increased True Positives (more customer's defaulting) and reduced false positives - from stacked / validation set to test set. This also indicates a better accuracy achieved on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we capture the feature importance for the Extra Trees Classifer, sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BILL_AMT6 0.00108048461406\n",
      "BILL_AMT5 0.00152516321207\n",
      "PAY_AMT4 0.00162780441778\n",
      "BILL_AMT4 0.00265519204382\n",
      "PAY_AMT3 0.00266480822751\n",
      "PAY_AMT2 0.00290465577983\n",
      "BILL_AMT3 0.00346693738116\n",
      "BILL_AMT2 0.00353706465493\n",
      "PAY_AMT1 0.00356014528872\n",
      "BILL_AMT1 0.00422883550691\n",
      "PAY_AMT6 0.00504973654066\n",
      "PAY_6 0.00520091925493\n",
      "PAY_AMT5 0.00684018186448\n",
      "EDUCATION 0.00766299514003\n",
      "SEX 0.0128472456469\n",
      "PAY_4 0.0669824452564\n",
      "PAY_2 0.0693010642019\n",
      "LIMIT_BAL 0.0822968707389\n",
      "PAY_3 0.0892769408027\n",
      "PAY_5 0.111961144154\n",
      "PAY_0 0.140367203638\n",
      "MARRIAGE 0.168657330985\n",
      "AGE 0.18130483065\n"
     ]
    }
   ],
   "source": [
    "for name, score in sorted(zip(ModelStacking_df_X.columns, ExtraClassifier_Estimators.feature_importances_), key=lambda x: x[1]):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a better accuracy on the test set when compared with the training set, Extra Trees proves out to be a good classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 288 candidates, totalling 1152 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1152 out of 1152 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 6, 'max_leaf_nodes': 3, 'min_samples_leaf': 3, 'min_samples_split': 0.2, 'n_estimators': 7}\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=6, max_leaf_nodes=3, min_impurity_decrease=0.0,\n",
      "              min_impurity_split=None, min_samples_leaf=3,\n",
      "              min_samples_split=0.2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=7, presort='auto', random_state=42,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "GB_Classifier = GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "n_estimators = [3, 7]\n",
    "learning_rate = [0.1, 0.01, .001]\n",
    "max_depth = [3, 15, 20]\n",
    "min_samples_split = [0.2, 0.3]\n",
    "min_samples_leaf = [3, 4]\n",
    "max_features = [4, 6]\n",
    "max_leaf_nodes = [2, 3]\n",
    "                            \n",
    "parameter_GB_Classifier = {'n_estimators' : n_estimators, 'learning_rate' : learning_rate,\n",
    "                              'max_depth' : max_depth, 'min_samples_split' : min_samples_split,\n",
    "                              'min_samples_leaf' : min_samples_leaf, 'max_features' : max_features,\n",
    "                              'max_leaf_nodes' : max_leaf_nodes}\n",
    "\n",
    "grid_search_GB_Classifier = GridSearchCV(GB_Classifier, parameter_GB_Classifier, cv = 4, scoring='roc_auc', \n",
    "                               refit = True, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_GB_Classifier.fit(Final_training_X,training_df_Y)\n",
    "\n",
    "GB_Classifier_best_params_ = grid_search_GB_Classifier.best_params_\n",
    "\n",
    "GB_Classifier_best_estimators_ = grid_search_GB_Classifier.best_estimator_\n",
    "\n",
    "print(GB_Classifier_best_params_)\n",
    "\n",
    "print(GB_Classifier_best_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774888888889\n"
     ]
    }
   ],
   "source": [
    "#Now Predict on the Stack Dataset\n",
    "GB_estimators = GB_Classifier_best_estimators_\n",
    "y_estimator_GB = GB_estimators.predict(Final_stack_X)\n",
    "print(accuracy_score(ModelStacking_df_Y, y_estimator_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776222222222\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy on the Test Data\n",
    "y_final_estimator_GB = GB_estimators.predict(Final_test_X)\n",
    "print(accuracy_score(test_df_Y, y_final_estimator_GB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we identify certain types of events that are classified better/worse from Gradient Boosting classifier - we use the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3487,    0],\n",
       "       [1013,    0]], dtype=int64)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the stack set for GB Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ModelStacking_df_Y, y_estimator_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3493,    0],\n",
       "       [1007,    0]], dtype=int64)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the test set for GB Classifier\n",
    "confusion_matrix(test_df_Y, y_final_estimator_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting model also receives higher True Positives (more customer's defaulting) and lower false positives - from stacked / validation set to test set. This also indicates a better accuracy achieved on test set.\n",
    "\n",
    "Now we capture the feature importance for the Gradient Boosting Classifer, sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BAL 0.0\n",
      "SEX 0.0\n",
      "EDUCATION 0.0\n",
      "PAY_0 0.0\n",
      "PAY_4 0.0\n",
      "PAY_6 0.0\n",
      "BILL_AMT1 0.0\n",
      "BILL_AMT2 0.0\n",
      "BILL_AMT3 0.0\n",
      "BILL_AMT4 0.0\n",
      "BILL_AMT5 0.0\n",
      "BILL_AMT6 0.0\n",
      "PAY_AMT1 0.0\n",
      "PAY_AMT5 0.0\n",
      "PAY_AMT6 0.0\n",
      "PAY_AMT2 0.0104714350208\n",
      "PAY_5 0.0124766227619\n",
      "PAY_AMT3 0.0125123496832\n",
      "PAY_3 0.016614420628\n",
      "PAY_AMT4 0.026053977783\n",
      "PAY_2 0.259660307931\n",
      "AGE 0.260725313269\n",
      "MARRIAGE 0.401485572923\n"
     ]
    }
   ],
   "source": [
    "for name, score in sorted(zip(ModelStacking_df_X.columns, GB_estimators.feature_importances_), key=lambda x: x[1]):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the model accuracy for Gradient Boosting Classifier is lower on the Test Set. The Lower variance could be due to the number of hyper parameters and their values. It is always recommended to check different hyper parameters. The model thus is still performing well and is not a case of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.3}\n",
      "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Create the Logistic Regression model\n",
    "\n",
    "Logistic_Regression = LogisticRegression(random_state = 42)\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "                            \n",
    "parameter_LogReg = {'C' : C}\n",
    "grid_search_LogReg = GridSearchCV(Logistic_Regression, parameter_LogReg, cv = 4, scoring='roc_auc', \n",
    "                               refit = True, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_LogReg.fit(Final_training_X,training_df_Y)\n",
    "LogReg_best_params_ = grid_search_LogReg.best_params_\n",
    "LogReg_best_estimators_ = grid_search_LogReg.best_estimator_\n",
    "\n",
    "print(LogReg_best_params_)\n",
    "print(LogReg_best_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801111111111\n"
     ]
    }
   ],
   "source": [
    "#Now Predict on the Stack Dataset\n",
    "LogReg_estimators = LogReg_best_estimators_ \n",
    "y_estimator_LogReg = LogReg_estimators.predict(Final_stack_X)\n",
    "print(accuracy_score(ModelStacking_df_Y, y_estimator_LogReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738888888889\n"
     ]
    }
   ],
   "source": [
    "y_final_estimator_LogReg = LogReg_estimators.predict(Final_stack_X)\n",
    "print(accuracy_score(test_df_Y, y_final_estimator_LogReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we identify certain types of events that are classified better/worse from Logistic Regression - we use the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3378,  109],\n",
       "       [ 786,  227]], dtype=int64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the stack set for Logistic Regression Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ModelStacking_df_Y, y_estimator_LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3241,  252],\n",
       "       [ 923,   84]], dtype=int64)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the confusion Matrix on the test set for Logistic Regression Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_df_Y, y_final_estimator_LogReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logistic regression model, we can observe that True Positives and False Negatives have dropped significantly (the defaults on the credit have reduced) from Stack Set to the test set. This is a good indication of overfitting of data on the stack set. This can also be observed based on the variance in the accuracy of Training and Test Set, The Logistic Regression model is an ideal case of overfitting.\n",
    "\n",
    "##### Please Note: We can't run the feature importance on the Logistic Regression\n",
    "\n",
    "So the Best Models are Random Forest, Gradient Boosting and Extra Trees Classifier - As they fit the data well.Since these models are heavy on Hyper Parameters, we can say that more Hyper parameters improves the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion on Feature Importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classifiers that support Feature importance. We can say that feature importance is not consistent for all the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART B of the Second Question\n",
    "- Stack your models. \n",
    "  - Combine the models from the previous section using the stacking approach: \n",
    "    - Choose the model use to combine. Examples are:\n",
    "      - Linear Regression\n",
    "      - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 5)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now build the Stacking model\n",
    "import numpy as np\n",
    "\n",
    "Final_Stacking_X = np.vstack((y_estimator_forest, y_estimator_ada, y_estimator_extra, \n",
    "                                 y_final_estimator_GB, y_estimator_LogReg))\n",
    "\n",
    "Final_Stacking_X = Final_Stacking_X.T\n",
    "Final_Stacking_X.shape # now we get the right number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "{'C': 0.0001}\n",
      "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Additionally we can check the Stack performance on the Logistic Regression model, \n",
    "\n",
    "Logistic_Regression = LogisticRegression(random_state = 42)\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "                            \n",
    "parameter_LogReg = {'C' : C}\n",
    "grid_search_LogReg = GridSearchCV(Logistic_Regression, parameter_LogReg, cv = 4, scoring='roc_auc', \n",
    "                               refit = True, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_LogReg.fit(Final_Stacking_X,ModelStacking_df_Y)\n",
    "LogReg_New_best_params = grid_search_LogReg.best_params_\n",
    "LogReg_New_best_estimators = grid_search_LogReg.best_estimator_\n",
    "\n",
    "print(LogReg_New_best_params)\n",
    "print(LogReg_New_best_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774888888889\n"
     ]
    }
   ],
   "source": [
    "# Now check the accuracy of the Stacked Training set with the original Model Stacking Y.\n",
    "y_estimator_LogReg = LogReg_New_best_estimators.predict(Final_Stacking_X)\n",
    "print(accuracy_score(ModelStacking_df_Y, y_estimator_LogReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776222222222\n"
     ]
    }
   ],
   "source": [
    "# Now check the accuracy of the Stacked Training set with the original Test Y\n",
    "y_final_estimator_LogReg = LogReg_New_best_estimators.predict(Final_Stacking_X)\n",
    "print(accuracy_score(test_df_Y,y_estimator_LogReg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### The Stack approach works well with the logistic regression as the accuracy improves on the test set when compared with the original stack/validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If a Decision Tree is overfitting the training set, is it a good idea to try decreasing max_depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a Decision Tree is overfitting the training set, it may be a good idea to decrease max_depth, since it will constrain the model and regularize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Decision Trees, a small change in the data can lead to completely different boundaries. Scaling here would be a bad idea, instead use hyper-parameters for regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) What is the difference between hard and soft voting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hard voting classifier counts the votes of each classifier in the ensemble and picks the class that gets the most votes. A soft voting classifier computes the average estimated class probability for each class and picks the class with the highest probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If your AdaBoost ensemble underfits the training data, what hyperparameters should you tweak and how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your AdaBoost ensemble underfits the training data,  Relaxing the hyperparameters by adding more estimators or increasing a learning rate may help. Heavy regularized model will lead to underfitting on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. (Optional) If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you Gradient Boosting ensemble model overfits the training set, you should try decreasing the learning rate. \n",
    "\n",
    "Incase of overfitting on the training set, decrease hyperparameters (more regularization)\n",
    "Or else increase hyperparameters (less regularization) in case of underfitting."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
