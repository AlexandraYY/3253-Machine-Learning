{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> Ashish Gupta</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Enter the name of the people you worked with if any</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown referece can be found here:\n",
    "    http://nestacms.com/docs/creating-content/markdown-cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Why would it be a problem if our training set and test set are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>Training set is used to build the model / classifer and fit the parameters. Once the model is build and validated,\n",
    "\n",
    "the test / unseen data is fed into the model to get the new predicted values. If the training and test set are the \n",
    "same,it will lead to a problem of overfitting, as the model will correctly predict all the data points, it was initially \n",
    "trained on. \n",
    "\n",
    "The reason for overfitting is that the model is not as generalized, as it could be - using an unseen or new test data. \n",
    "Instead It has adopted itself to the structure in the training dataset to generate accuracy.   \n",
    "\n",
    "Therefore the techniques like the model comparison, regularization, pruning, N-Folds Cross Validation are recommended \n",
    "to lessen the chances of overfitting. \n",
    "\n",
    "However There is a possible scenario (outside machine learning) where we train the model and evaluate it using the \n",
    "same dataset. This Scenario is called Descriptive Model, where we describe the data on which the model has been trained. \n",
    "the descriptive models helps understanding how the key attributes of the model are related to the predictive values. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 [OPTIONAL]. Explain step by step the process to select k in the k-nearest neighbor algorithm (pseudocode) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>1. Split the data into similarly-sized subsets using N-Folds cross validation technique.\n",
    "\n",
    "2. Hold out the first set. Train your classifier on the remaining data. \n",
    "\n",
    "   Let (Xi, Ci) where i = 1, 2…… n be data points. Xi denotes feature values and Ci denotes labels for Xi for each i.\n",
    "   Assuming the number of classes as ‘C’\n",
    "\n",
    "   Ci ∈ {1, 2, 3, ……, c} for all values of i\n",
    "\n",
    "   Calculate “d(x, xi)” i =1, 2, ….., n; where d denotes the Euclidean distance between the points.\n",
    "   Arrange the calculated n Euclidean distances in increasing order.\n",
    "\n",
    "   Let k be a +ve integer, take the first k distances from this sorted list.\n",
    "   Find those k-points corresponding to these k-distances.\n",
    " \n",
    "   Let ki denotes the number of points belonging to the ith class among k points i.e. k ≥ 0\n",
    "   If ki >kj ∀ i ≠ j then put x in class i.\n",
    "\n",
    "3. Classify each point in the validation set, using its kk nearest neighbors in (Xi, Ci)\n",
    "\n",
    "4. Record the error.\n",
    "\n",
    "5. Repeat steps 1-4 for all N choices of the validation set.\n",
    "\n",
    "6. For each choice of N, find the average error across validation sets. Choose the value of N with the lowest error.\n",
    "\n",
    "7. Construct a final classifier using all of the original data and the chosen value of k. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. For the k-nearest regression. What happends when k = n. Where n is equal to the training size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>Once the value of K becomes too large, we may loose the important details in the distribution, and as we choose k \n",
    "to be equal to the number of number data points - it is computationally expensive and will oversimplify the distribution (depending on the total majority)</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Define a function that takes a 1-d numpy array, a parameter k, and a number p.\n",
    "The function returns an estimate equal to the mean of the closest k points to the number p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import os\n",
    "\n",
    "def euclideanDistance(instance1,instance2,k):\n",
    "    distance = 0\n",
    "    for x in range(0, k):\n",
    "        distance += pow((instance1 - instance2), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def k_neighbor(input_data, k, p):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    \n",
    "    If you make assumptions please explain them in the comments. i.e. tie breaking strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    mean_neighbors = []\n",
    "    distances = []\n",
    "    for x in range(len(input_data)):\n",
    "        dist = euclideanDistance(input_data[x],p,k)\n",
    "        distances.append((input_data[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1)) # Tie breaking strategy to sort the closest members in KNN\n",
    "    \n",
    "    for x in range(0,k):\n",
    "        mean_neighbors.append(distances[x][0])\n",
    "        \n",
    "    return \"The neighbors & distances are:\", distances[0:k],\" the average is \", np.average(mean_neighbors[0:k])\n",
    "  \n",
    "#return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The neighbors & distances are:', [(5, 0.0), (4, 1.7320508075688772), (3, 3.4641016151377544)], ' the average is ', 4.0)\n",
      "('The neighbors & distances are:', [(15, 0.0), (13, 2.8284271247461903)], ' the average is ', 14.0)\n",
      "('The neighbors & distances are:', [(25, 0.0), (24, 1.7320508075688772), (29, 6.928203230275509)], ' the average is ', 26.0)\n",
      "('The neighbors & distances are:', [(40, 15.0)], ' the average is ', 40.0)\n",
      "('The neighbors & distances are:', [(40, 25.98076211353316), (29, 45.033320996790806), (25, 51.96152422706632)], ' the average is ', 31.333333333333332)\n",
      "('The neighbors & distances are:', [(40, 33.54101966249684), (29, 58.137767414994535), (25, 67.08203932499369), (24, 69.31810730249349), (19, 80.49844718999243)], ' the average is ', 27.399999999999999)\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "import numpy as np\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor(input_data=data, k=3, p=5))\n",
    "print(k_neighbor(input_data=data, k=2, p=15))\n",
    "print(k_neighbor(input_data=data, k=3, p=25))\n",
    "print(k_neighbor(input_data=data, k=1, p=55))\n",
    "print(k_neighbor(input_data=data, k=3, p=55))\n",
    "print(k_neighbor(input_data=data, k=5, p=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The output highlights the smallest mean when k=3, p=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Similar to Q4 but for the n dimentional case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "def l1_norm(a,b):\n",
    "    return sum(map(lambda a:abs(a[0]-a[1]), zip(a,b)))\n",
    "\n",
    "    \"\"\"Returns the l1 norm (a,b)\"\"\"\n",
    "    \n",
    "def l2_norm(a,b):\n",
    "    distance = sum(map(lambda a:pow(abs(a[0]-a[1]),2), zip(a,b)))\n",
    "    return math.sqrt(distance)\n",
    "  \n",
    "    \"\"\"Returns the l2 norm (a,b)\"\"\" \n",
    "    \n",
    "def k_neighbor_nd(input_data, k, p, metric, mode):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    metric -- l1 or l2. l1 norm or l2 norm https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "    mode -- estimator possible values = 'mean', 'median', 'max'\n",
    "    \n",
    "    Implement the l1 and l2 norms\n",
    "    for mean, median and max, use np.mean, np.median and np.max\n",
    "    \"\"\"\n",
    "    \n",
    "    #YOUR CODE HERE  \n",
    "    distance = []\n",
    "    Stat_Neighbors = []\n",
    "    for x in range(0,input_data.shape[0]-1):\n",
    "        if metric == \"l1\":\n",
    "            dist = l1_norm(input_data[x],p)\n",
    "        if metric == \"l2\":\n",
    "            dist = l2_norm(input_data[x],p)\n",
    "        distance.append((input_data[x], dist))\n",
    "        distance.sort(key=operator.itemgetter(1))\n",
    "   \n",
    "    for x in range(0,k):\n",
    "        Stat_Neighbors.append(distance[x][0])\n",
    "   #return Stat_Neighbors,np.average(Stat_Neighbors, axis = 0)\n",
    "\n",
    "    if mode == \"mean\":\n",
    "        return \"The neighbors & distances are:\", distance[0:k],\" and the average is \", np.average(Stat_Neighbors[0:k], axis = 0)\n",
    "    elif mode == \"max\":\n",
    "        return \"The neighbors & distances are:\", distance[0:k],\" and the max is \", np.max(Stat_Neighbors[0:k], axis = 0)\n",
    "    elif mode ==\"median\":\n",
    "        return \"The neighbors & distances are:\", distance[0:k],\" and the median is \", np.median(Stat_Neighbors[0:k], axis = 0)\n",
    "        \n",
    "    #return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_4d = np.array([[4, 1, 2, 1], [1, 4, 2, 0], [3, 3, 1, 1], \n",
    "        [4, 0, 0, 0], [1, 2, 0, 0], [3, 4, 2, 3], \n",
    "        [2, 4, 4, 2], [2, 1, 4, 1], [3, 3, 2, 4], \n",
    "        [4, 3, 0, 4], [2, 2, 4, 0],[4, 3, 0, 2], \n",
    "        [4, 3, 0, 2], [0, 3, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The neighbors & distances are:', [(array([2, 1, 4, 1]), 2), (array([2, 4, 4, 2]), 4), (array([2, 2, 4, 0]), 4)], ' and the average is ', array([ 2.        ,  2.33333333,  4.        ,  1.        ]))\n",
      "('The neighbors & distances are:', [(array([4, 3, 0, 2]), 3), (array([4, 3, 0, 2]), 3)], ' and the average is ', array([ 4.,  3.,  0.,  2.]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 2, 4]), 2), (array([3, 4, 2, 3]), 4), (array([4, 3, 0, 4]), 5)], ' and the max is ', array([4, 4, 2, 4]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 2, 4]), 2)], ' and the average is ', array([ 3.,  3.,  2.,  4.]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 2, 4]), 2), (array([3, 4, 2, 3]), 4), (array([2, 4, 4, 2]), 4)], ' and the median is ', array([ 3.,  4.,  2.,  3.]))\n",
      "('The neighbors & distances are:', [(array([2, 1, 4, 1]), 2.0), (array([2, 4, 4, 2]), 3.1622776601683795), (array([3, 3, 2, 4]), 3.1622776601683795)], ' and the average is ', array([ 2.33333333,  2.66666667,  3.33333333,  2.33333333]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 1, 1]), 2.0), (array([4, 3, 0, 2]), 2.23606797749979)], ' and the average is ', array([ 3.5,  3. ,  0.5,  1.5]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 2, 4]), 1.4142135623730951), (array([3, 4, 2, 3]), 2.449489742783178), (array([4, 3, 0, 4]), 3.0)], ' and the max is ', array([4, 4, 2, 4]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 2, 4]), 1.4142135623730951)], ' and the average is ', array([ 3.,  3.,  2.,  4.]))\n",
      "('The neighbors & distances are:', [(array([3, 3, 2, 4]), 1.4142135623730951), (array([3, 4, 2, 3]), 2.0), (array([2, 4, 4, 2]), 2.449489742783178)], ' and the median is ', array([ 3.,  4.,  2.,  3.]))\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l1', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l1', mode='median'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l2', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l2', mode='median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enter your observations and comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6[Optional]. Read the documentation on KNeighborsRegressor\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    \n",
    "Explore the source code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/neighbors/regression.py\n",
    "        \n",
    "How different it is from your implementation? How well can you follow the code? Did you learn something new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>My implementation didn't include - importing the KNeighborsRegressor library. Using Predictive methodology - \n",
    "KNeighborsRegressor is able to predit the neighbors for the training data.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
